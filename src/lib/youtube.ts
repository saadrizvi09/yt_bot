import { AssemblyAI } from 'assemblyai';
import { YtDlp, YtDlpConfig } from '@yemreak/yt-dlp';
import fs from 'fs';
import path from 'path';
import { pipeline } from 'stream/promises';
import { execFile } from 'child_process'; // Import execFile

const ytDlpConfig: YtDlpConfig = { workdir: path.join(process.cwd(), 'temp') };
const ytDlp = new YtDlp(ytDlpConfig);

// Ensure yt-dlp executable is downloaded when the application starts
(async () => {
  try {
    console.log('Ensuring yt-dlp executable is present...');
    await ytDlp.downloadLatestReleaseIfNotExists();
    console.log('yt-dlp executable check complete.');
  } catch (error) {
    console.error('Error ensuring yt-dlp executable presence:', error);
  }
})();

// Extract YouTube video ID from URL
export function extractVideoId(url: string): string | null {
  const regex = /(?:youtube\.com\/(?:[^\/\n\s]+\/\S+\/|(?:v|e(?:mbed)?)\/|\S*?[?&]v=)|youtu\.be\/)([a-zA-Z0-9_-]{11})/;
  const match = url.match(regex);
  return match ? match[1] : null;
}

// Fetch video details (title, duration)
export async function getVideoDetails(videoId: string) {
  try {
    // Using YouTube oEmbed API which doesn't require API key
    const response = await fetch(`https://www.youtube.com/oembed?url=https://www.youtube.com/watch?v=${videoId}&format=json`);
    
    if (!response.ok) {
      throw new Error('Failed to fetch video details');
    }
    
    const data = await response.json();
    
    return {
      title: data.title,
      duration: 0, // Will be updated after transcription
    };
  } catch (error) {
    console.error('Error fetching video details:', error);
    throw error;
  }
}

// Download audio from YouTube video
export async function downloadAudio(youtubeUrl: string): Promise<string> {
  try {
    const videoId = extractVideoId(youtubeUrl);
    if (!videoId) {
      throw new Error('Invalid YouTube URL');
    }

    const tempDir = path.join(process.cwd(), 'temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    const audioPath = path.join(tempDir, `${videoId}.mp3`);

    if (fs.existsSync(audioPath)) {
      console.log('Audio file already exists, using cached version');
      return audioPath;
    }

    console.log('Downloading audio to:', audioPath);

    // Download video using yt-dlp to get the audio
    try {
      const downloadedPaths = await ytDlp.download({
        url: youtubeUrl,
        format: 'ba',
      });

      if (downloadedPaths.length === 0) {
        throw new Error('No audio file was downloaded by yt-dlp.');
      }

      // The downloaded file name might not be exactly `${videoId}.mp3`, it can include title etc.
      // We need to find the correct audio file path in the temp directory.
      // For now, we'll assume the first downloaded path is the audio file we want.
      const actualAudioPath = downloadedPaths[0];

      console.log('Audio download completed');
      return actualAudioPath;
    } catch (ytDlpError: any) {
      console.error('yt-dlp download error:', ytDlpError.message);
      throw new Error(`Failed to download audio: ${ytDlpError.message}`);
    }

  } catch (error:any) {
    console.error('Error downloading audio:', error);
    throw new Error(`Failed to download audio: ${error.message}`);
  }
}

// Get auto-generated captions using yt-dlp
export async function getAutoGeneratedTranscriptWithYtDlp(videoId: string): Promise<string | null> {
  try {
    console.log(`Attempting to fetch auto-generated transcript for video ${videoId} with yt-dlp...`);
    
    const ytDlpExecutablePath = path.join(ytDlpConfig.workdir!, 'yt-dlp.exe');

    // First, get video info to check for available auto-generated captions
    let mediaInfo: any;
    try {
      const infoArgs = [
        `https://www.youtube.com/watch?v=${videoId}`,
        '--dump-json',
        '--skip-download',
      ];
      console.log(`Executing yt-dlp info command: ${ytDlpExecutablePath} ${infoArgs.join(' ')}`);

      const infoOutput = await new Promise<string>((resolve, reject) => {
        execFile(ytDlpExecutablePath, infoArgs, (error, stdout, stderr) => {
          if (error) {
            console.error(`yt-dlp info stdout: ${stdout}`);
            console.error(`yt-dlp info stderr: ${stderr}`);
            return reject(error);
          }
          resolve(stdout);
        });
      });
      mediaInfo = JSON.parse(infoOutput);
      console.log('yt-dlp mediaInfo (partial):', { id: mediaInfo.id, title: mediaInfo.title, automatic_captions_keys: mediaInfo.automatic_captions ? Object.keys(mediaInfo.automatic_captions) : 'none' });

    } catch (infoError: any) {
      console.error(`Error getting yt-dlp info for video ${videoId}:`, infoError.message);
      return null; // Cannot proceed without info
    }

    if (!mediaInfo || !mediaInfo.automatic_captions) {
      console.warn(`No automatic_captions found in yt-dlp info for video ${videoId}.`);
      return null;
    }

    // Check if English auto-generated captions exist
    const availableAutoCaptions = mediaInfo.automatic_captions;
    let hasEnglishAutoCaption = false;
    if (availableAutoCaptions.en && availableAutoCaptions.en.length > 0) {
      hasEnglishAutoCaption = true;
    } else if (availableAutoCaptions['en-US'] && availableAutoCaptions['en-US'].length > 0) {
      hasEnglishAutoCaption = true;
    } else if (availableAutoCaptions['en-GB'] && availableAutoCaptions['en-GB'].length > 0) {
      hasEnglishAutoCaption = true;
    }

    console.log(`hasEnglishAutoCaption check result: ${hasEnglishAutoCaption}`);

    if (!hasEnglishAutoCaption) {
      console.warn(`No English auto-generated captions found for video ${videoId} based on yt-dlp info.`);
      return null;
    }

    let tempSubtitlePath = path.join(ytDlpConfig.workdir!, `${videoId}.en.vtt`); // Expect .vtt output

    // Command to get auto-generated English subtitles in VTT format (no conversion by yt-dlp)
    const args = [
      `https://www.youtube.com/watch?v=${videoId}`,
      '--write-auto-subs', // Write auto-generated subtitles
      '--sub-langs', 'en', // Specify English auto-generated subtitles
      '--skip-download', // Only download subtitles, not the video
      '--output', tempSubtitlePath, // Specify output file path as .vtt
    ];

    console.log(`Executing yt-dlp command: ${ytDlpExecutablePath} ${args.join(' ')}`);

    // Execute yt-dlp directly using child_process
    await new Promise<void>((resolve, reject) => {
      execFile(ytDlpExecutablePath, args, (error, stdout, stderr) => {
        if (error) {
          console.error(`yt-dlp stdout: ${stdout}`);
          console.error(`yt-dlp stderr: ${stderr}`);
          return reject(error);
        }
        // Log stdout and stderr even if no error for debugging
        if (stdout) console.log(`yt-dlp subtitle stdout: ${stdout}`);
        if (stderr) console.error(`yt-dlp subtitle stderr: ${stderr}`);
        resolve();
      });
    });

    // Before checking fs.existsSync, check the temp directory contents
    const filesInTemp = fs.readdirSync(ytDlpConfig.workdir!);
    console.log('Files in temp directory:', filesInTemp);

    if (!fs.existsSync(tempSubtitlePath)) {
      // Check for files that might contain the videoId and have a .vtt or .srt extension
      const potentialSubtitleFiles = filesInTemp.filter(file => 
        file.includes(videoId) && (file.endsWith('.vtt') || file.endsWith('.srt'))
      );
      
      if (potentialSubtitleFiles.length > 0) {
        const actualDownloadedPath = path.join(ytDlpConfig.workdir!, potentialSubtitleFiles[0]);
        console.log(`Found a potential subtitle file: ${actualDownloadedPath}. Using this instead of ${tempSubtitlePath}.`);
        tempSubtitlePath = actualDownloadedPath; // Update path to the actual downloaded file
      } else {
        console.warn(`yt-dlp did not create the auto-generated subtitle file at ${tempSubtitlePath}. No other subtitle files found.`);
        return null;
      }
    }

    const subtitleContent = fs.readFileSync(tempSubtitlePath, 'utf-8');
    fs.unlinkSync(tempSubtitlePath); // Clean up the temporary file

    if (!subtitleContent || subtitleContent.trim().length === 0) {
      console.warn(`Extracted auto-generated subtitle content is empty for video ${videoId}.`);
      return null;
    }

    // Parse WebVTT to extract text only
    // Remove WEBVTT header and any note lines at the beginning
    const cleanedContent = subtitleContent.replace(/^WEBVTT(?:\s+Kind:.*)?(?:\s+Language:.*)?\n(?:NOTE.*\n)*\n/, '');

    const textOnlyTranscript = cleanedContent
      .split(/\n\n/) // Splits into cue blocks
      .map(block => {
        const lines = block.split(/\n/);
        // A cue block typically starts with an optional ID, then timestamp, then text
        // We want to extract only the text, and remove inline timestamps/tags
        const textLines = lines.filter(line => !line.match(/^\d+$/) && !line.match(/^\d{2}:\d{2}:\d{2}\.\d{3}/));
        // Remove inline VTT timestamps and <c> tags like <00:00:00.000><c> and </c>
        return textLines.join(' ').replace(/<\d{2}:\d{2}:\d{2}\.\d{3}>/g, '').replace(/<c[^>]*>|<\/c>/g, '');
      })
      .filter(Boolean) // Remove empty strings that might result from header/timestamp-only blocks
      .join(' ')
      .replace(/\s+/g, ' ') // Replace multiple spaces with a single space
      .trim();

    console.log(`Successfully fetched auto-generated transcript for video ${videoId} with yt-dlp exec, length: ${textOnlyTranscript.length}`);
    return textOnlyTranscript;
  } catch (error: any) {
    console.error(`Error fetching auto-generated transcript with yt-dlp exec for video ${videoId}:`, error.message);
    return null;
  }
}

// Transcribe audio using AssemblyAI
export async function transcribeWithAssemblyAI(audioPath: string) {
  try {
    const apiKey = process.env.ASSEMBLYAI_API_KEY;
    if (!apiKey) {
      throw new Error('Missing AssemblyAI API key in environment variables');
    }

    console.log('Initializing AssemblyAI client...');
    const client = new AssemblyAI({
      apiKey,
    });

    console.log('Starting transcription...');
    
    // Upload and transcribe the audio file
    const transcriptResponse = await client.transcripts.transcribe({
      audio: audioPath,
      language_detection: true, // Enable automatic language detection
      sentiment_analysis: false,
      auto_chapters: false,
      auto_highlights: false,
      speaker_labels: false,
      entity_detection: false,
      iab_categories: false,
      summarization: false,
      word_boost: [], // Add important words if needed
      boost_param: "default",
    });

    console.log('Transcription status:', transcriptResponse.status);

    if (transcriptResponse.status === "error") {
      console.error('AssemblyAI full error response:', transcriptResponse);
      throw new Error(`AssemblyAI Error: ${transcriptResponse.error}`);
    }

    if (!transcriptResponse.text) {
      throw new Error("No text found in transcript from AssemblyAI");
    }

    console.log('Transcription completed successfully');
    
    // Clean up the audio file after successful transcription
    try {
      fs.unlinkSync(audioPath);
      console.log('Cleaned up audio file');
    } catch (cleanupError) {
      console.warn('Could not clean up audio file:', cleanupError);
    }

    // Return the full transcript text
    return transcriptResponse.text;

  } catch (error:any) {
    console.error('Error transcribing audio:', error);
    
    // Clean up audio file on error too
    try {
      if (fs.existsSync(audioPath)) {
        fs.unlinkSync(audioPath);
      }
    } catch (cleanupError) {
      console.warn('Could not clean up audio file after error:', cleanupError);
    }
    
    throw new Error(`Failed to transcribe audio: ${error.message}`);
  }
}
export function chunkTranscript(transcript: string, chunkSize: number = 2000) {
  // First clean the WEBVTT format by removing timestamps and tags
  let cleanedTranscript = transcript
    .replace(/WEBVTT.*\n\n/, '') // Remove WEBVTT header
    .replace(/<00:\d{2}:\d{2}\.\d{3}><c> /g, '') // Remove timestamps like <00:00:05.123><c>
    .replace(/<\/c>/g, '') // Remove closing tags like </c>
    .replace(/<c>.*?<\/c>/g, '') // Remove any remaining tags like <c.color> or <c> (if not caught by timestamp removal)
    .replace(/\n/g, ' ') // Replace newlines with spaces
    .replace(/\s+/g, ' ') // Collapse multiple spaces
    .trim();

  // --- Start of Repetition Removal ---
  // This loop iteratively removes immediate repetitions of words or phrases.
  // It continues until no more repetitions of the defined pattern are found,
  // effectively collapsing "A A A" to "A".
  let oldTranscript: string;
  do {
    oldTranscript = cleanedTranscript;
    // Regex to find a sequence of 1 to 15 "word-like" tokens (non-whitespace characters)
    // followed by one or more spaces, and then the exact same sequence.
    //
    // Breakdown of the regex:
    // (\b(?:[^\s]+\s+){0,14}?[^\s]+\b)
    //   - \b: Word boundary, ensures we match whole words/phrases.
    //   - (?: ... ): A non-capturing group.
    //   - [^\s]+\s+: Matches one or more non-whitespace characters (a "word")
    //                followed by one or more whitespace characters.
    //   - {0,14}?: This repeats the "word + space" pattern 0 to 14 times,
    //              making the phrase 1 to 15 words long. The `?` makes it non-greedy,
    //              so it matches the shortest possible repeating unit first.
    //   - [^\s]+\b: Matches the last word of the phrase, followed by a word boundary.
    // This entire first part is captured as Group 1 `(...)`.
    //
    // \s+\1: Matches one or more spaces followed by the exact content of Group 1 (the repeated phrase).
    //
    // The `g` flag ensures all occurrences in the string are replaced.
    cleanedTranscript = cleanedTranscript.replace(/(\b(?:[^\s]+\s+){0,14}?[^\s]+\b)\s+\1/g, '$1');

    // After each replacement, collapse multiple spaces again to ensure clean boundaries
    // and trim any leading/trailing spaces that might result from replacements.
    cleanedTranscript = cleanedTranscript.replace(/\s+/g, ' ').trim();
  } while (cleanedTranscript !== oldTranscript); // Loop until no more changes occur in the string
  // --- End of Repetition Removal ---

  const chunks: {
    text: string;
    startTime: number;
    endTime: number;
    index: number;
  }[] = [];

  // Split cleaned transcript into sentences using the original logic provided
  const sentences = cleanedTranscript.split(/[.!?]+/).filter(s => s.trim().length > 0);

  let currentChunk = '';
  let chunkIndex = 0;

  for (let i = 0; i < sentences.length; i++) {
    const sentence = sentences[i].trim();

    // If the sentence is empty after trimming (e.g., from multiple separators), skip it
    if (sentence.length === 0) {
      continue;
    }

    // Check if adding this sentence would exceed chunk size
    // `currentChunk.length + sentence.length + 2` estimates the length if a ". " separator is added.
    // `chunkSize * 1.2` provides a 20% buffer to allow sentences to naturally complete within a chunk,
    // preventing very short chunks if a sentence barely exceeds the `chunkSize`.
    // `currentChunk.length >= chunkSize` ensures a chunk is pushed if it's already at or over the target size.
    if (currentChunk.length > 0 && (currentChunk.length + sentence.length + 2 > chunkSize * 1.2 || currentChunk.length >= chunkSize)) {
      chunks.push({
        text: currentChunk.trim(),
        startTime: 0,
        endTime: 0,
        index: chunkIndex++,
      });
      currentChunk = sentence; // Start a new chunk with the current sentence
    } else {
      // Add the current sentence to the current chunk.
      // Add a period and space as a separator if it's not the very first part of the current chunk.
      currentChunk += (currentChunk.length > 0 ? '. ' : '') + sentence;
    }
  }

  // After the loop, add any remaining text as the last chunk
  if (currentChunk.trim().length > 0) {
    chunks.push({
      text: currentChunk.trim(),
      startTime: 0,
      endTime: 0,
      index: chunkIndex,
    });
  }
  console.log(`Created ${chunks.length} chunks from transcript`);
  return chunks;
}

// Alternative function  to get transcript with word-level timestamps
export async function getTranscriptWithTimestamps(youtubeUrl: string) {
  try {
    const audioPath = await downloadAudio(youtubeUrl);
    
    const apiKey = process.env.ASSEMBLYAI_API_KEY;
    if (!apiKey) {
      throw new Error('Missing AssemblyAI API key in environment variables');
    }

    const client = new AssemblyAI({
      apiKey,
    });

    const transcriptResponse = await client.transcripts.transcribe({
      audio: audioPath,
      language_detection: true, // Enable automatic language detection
    });

    if (transcriptResponse.status === "error") {
      throw new Error(`AssemblyAI Error: ${transcriptResponse.error}`);
    }

    if (!transcriptResponse.words) {
      throw new Error("No words found in transcript from AssemblyAI");
    }

    // Clean up audio file
    try {
      fs.unlinkSync(audioPath);
    } catch (cleanupError) {
      console.warn('Could not clean up audio file:', cleanupError);
    }

    // Transform AssemblyAI words into transcript format
    const transcript = transcriptResponse.words.map(word => ({
      text: word.text ?? '',
      offset: word.start / 1000, // Convert ms to seconds
      duration: (word.end - word.start) / 1000,
    }));

    let totalDuration = 0;
    if (transcript.length > 0) {
      const lastEntry = transcript[transcript.length - 1]!;
      totalDuration = Math.ceil(lastEntry.offset + lastEntry.duration);
    }
    
    return {
      transcript,
      duration: totalDuration,
    };
  } catch (error) {
    console.error('Error fetching transcript with timestamps:', error);
    throw error;
  }
}
